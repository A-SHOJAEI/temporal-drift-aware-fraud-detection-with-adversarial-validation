{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Drift-Aware Fraud Detection Exploration\n",
    "\n",
    "This notebook demonstrates the key features of the temporal drift-aware fraud detection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporal_drift_aware_fraud_detection_with_adversarial_validation.data.loader import DataLoader\n",
    "from temporal_drift_aware_fraud_detection_with_adversarial_validation.utils.config import load_config\n",
    "\n",
    "# Load configuration\n",
    "config = load_config('../configs/default.yaml')\n",
    "print(\"Configuration loaded successfully\")\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = DataLoader(random_seed=42)\n",
    "\n",
    "# Load synthetic data (mimics IEEE-CIS structure)\n",
    "train_data, test_data = data_loader.load_data()\n",
    "\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Train fraud rate: {train_data['isFraud'].mean():.4f}\")\n",
    "print(f\"Test fraud rate: {test_data['isFraud'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data structure\n",
    "feature_info = data_loader.get_feature_info(train_data)\n",
    "print(\"Dataset Information:\")\n",
    "for key, value in feature_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Transaction volume over time\n",
    "train_data['time_bin'] = pd.cut(train_data['TransactionDT'], bins=20)\n",
    "time_counts = train_data.groupby('time_bin').size()\n",
    "axes[0, 0].plot(range(len(time_counts)), time_counts.values)\n",
    "axes[0, 0].set_title('Transaction Volume Over Time')\n",
    "axes[0, 0].set_xlabel('Time Period')\n",
    "axes[0, 0].set_ylabel('Number of Transactions')\n",
    "\n",
    "# Fraud rate over time\n",
    "fraud_rate_over_time = train_data.groupby('time_bin')['isFraud'].mean()\n",
    "axes[0, 1].plot(range(len(fraud_rate_over_time)), fraud_rate_over_time.values, color='red')\n",
    "axes[0, 1].set_title('Fraud Rate Over Time')\n",
    "axes[0, 1].set_xlabel('Time Period')\n",
    "axes[0, 1].set_ylabel('Fraud Rate')\n",
    "\n",
    "# Transaction amount distribution\n",
    "axes[1, 0].hist(np.log1p(train_data['TransactionAmt']), bins=50, alpha=0.7, label='Normal')\n",
    "axes[1, 0].hist(np.log1p(train_data[train_data['isFraud'] == 1]['TransactionAmt']), \n",
    "                bins=50, alpha=0.7, label='Fraud', color='red')\n",
    "axes[1, 0].set_title('Log Transaction Amount Distribution')\n",
    "axes[1, 0].set_xlabel('Log(1 + Amount)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Hour of day patterns\n",
    "train_data['hour'] = (train_data['TransactionDT'] % (24 * 3600)) // 3600\n",
    "hourly_fraud = train_data.groupby('hour')['isFraud'].mean()\n",
    "axes[1, 1].bar(hourly_fraud.index, hourly_fraud.values)\n",
    "axes[1, 1].set_title('Fraud Rate by Hour of Day')\n",
    "axes[1, 1].set_xlabel('Hour')\n",
    "axes[1, 1].set_ylabel('Fraud Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporal_drift_aware_fraud_detection_with_adversarial_validation.data.preprocessing import FeatureEngineer, TemporalSplitter\n",
    "\n",
    "# Initialize feature engineer\n",
    "feature_engineer = FeatureEngineer(random_seed=42)\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Original features:\", train_data.shape[1])\n",
    "train_processed = feature_engineer.fit_transform(train_data)\n",
    "print(\"After feature engineering:\", train_processed.shape[1])\n",
    "\n",
    "# Show some engineered features\n",
    "print(\"\\nNew features created:\")\n",
    "original_cols = set(train_data.columns)\n",
    "new_cols = set(train_processed.columns) - original_cols\n",
    "for col in sorted(list(new_cols))[:10]:\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal splitting demonstration\n",
    "splitter = TemporalSplitter(random_seed=42)\n",
    "\n",
    "# Create drift periods\n",
    "drift_periods = splitter.create_drift_periods(train_data, n_periods=5)\n",
    "\n",
    "# Analyze drift across periods\n",
    "period_stats = []\n",
    "for i, period in enumerate(drift_periods):\n",
    "    stats = {\n",
    "        'period': i,\n",
    "        'size': len(period),\n",
    "        'fraud_rate': period['isFraud'].mean(),\n",
    "        'avg_amount': period['TransactionAmt'].mean(),\n",
    "        'time_range': f\"{period['TransactionDT'].min():.1f} - {period['TransactionDT'].max():.1f}\"\n",
    "    }\n",
    "    period_stats.append(stats)\n",
    "\n",
    "period_df = pd.DataFrame(period_stats)\n",
    "print(\"Drift periods analysis:\")\n",
    "print(period_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adversarial Validation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporal_drift_aware_fraud_detection_with_adversarial_validation.models.model import AdversarialValidator\n",
    "\n",
    "# Initialize adversarial validator\n",
    "adv_validator = AdversarialValidator(\n",
    "    model_type='lightgbm',\n",
    "    random_seed=42,\n",
    "    n_estimators=100  # Reduced for demo speed\n",
    ")\n",
    "\n",
    "# Use first two periods for demonstration\n",
    "source_period = drift_periods[0]\n",
    "target_period = drift_periods[-1]  # Last period (most drift)\n",
    "\n",
    "print(f\"Source period size: {len(source_period)}\")\n",
    "print(f\"Target period size: {len(target_period)}\")\n",
    "\n",
    "# Train adversarial validator\n",
    "metrics = adv_validator.fit(source_period, target_period)\n",
    "\n",
    "print(\"\\nAdversarial validation results:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "if metrics['drift_score'] > 0.6:\n",
    "    print(\"\\n⚠️  Significant drift detected!\")\n",
    "else:\n",
    "    print(\"\\n✅ Low drift detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Training Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporal_drift_aware_fraud_detection_with_adversarial_validation.training.trainer import DriftAwareTrainer\n",
    "\n",
    "# Create a small config for demo\n",
    "demo_config = config.to_dict()\n",
    "\n",
    "# Reduce model complexity for quick demo\n",
    "for model_name in demo_config.get('base_models', {}):\n",
    "    if 'params' in demo_config['base_models'][model_name]:\n",
    "        params = demo_config['base_models'][model_name]['params']\n",
    "        params['n_estimators'] = 50\n",
    "        if 'iterations' in params:\n",
    "            params['iterations'] = 50\n",
    "\n",
    "demo_config['training']['n_drift_periods'] = 3\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = DriftAwareTrainer(\n",
    "    config=demo_config,\n",
    "    save_dir='../models_demo'\n",
    ")\n",
    "\n",
    "# Use smaller sample for demo\n",
    "demo_data = train_data.sample(n=2000, random_state=42)\n",
    "\n",
    "print(\"Training ensemble on demo data...\")\n",
    "print(\"(This may take a few minutes)\")\n",
    "\n",
    "# Train the system\n",
    "results = trainer.train(demo_data, save_best=False)\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(\"Key results:\")\n",
    "for key, value in results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction and Drift Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "test_sample = test_data.sample(n=500, random_state=42)\n",
    "probs, preds = trainer.predict(test_sample)\n",
    "\n",
    "print(f\"Made predictions on {len(test_sample)} transactions\")\n",
    "print(f\"Predicted fraud rate: {preds.mean():.4f}\")\n",
    "print(f\"Actual fraud rate: {test_sample['isFraud'].mean():.4f}\")\n",
    "\n",
    "# Analyze prediction distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(probs[test_sample['isFraud'] == 0], bins=30, alpha=0.7, label='Normal', density=True)\n",
    "plt.hist(probs[test_sample['isFraud'] == 1], bins=30, alpha=0.7, label='Fraud', density=True)\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Prediction Distribution by True Label')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(test_sample['isFraud'], probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model contributions\n",
    "feature_cols = [col for col in test_sample.columns if col not in ['isFraud', 'TransactionID']]\n",
    "test_features = test_sample[feature_cols]\n",
    "\n",
    "contributions = trainer.ensemble.get_model_contributions(test_features)\n",
    "\n",
    "print(\"Individual model contributions:\")\n",
    "fig, axes = plt.subplots(1, len(contributions), figsize=(15, 4))\n",
    "\n",
    "if len(contributions) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (model_name, model_preds) in enumerate(contributions.items()):\n",
    "    axes[i].scatter(probs, model_preds, alpha=0.6)\n",
    "    axes[i].plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
    "    axes[i].set_xlabel('Ensemble Prediction')\n",
    "    axes[i].set_ylabel(f'{model_name} Prediction')\n",
    "    axes[i].set_title(f'{model_name} vs Ensemble')\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = np.corrcoef(probs, model_preds)[0, 1]\n",
    "    axes[i].text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "                transform=axes[i].transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show model weights\n",
    "print(\"\\nModel weights in ensemble:\")\n",
    "for name, weight in trainer.ensemble.model_weights.items():\n",
    "    print(f\"  {name}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calibration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temporal_drift_aware_fraud_detection_with_adversarial_validation.evaluation.metrics import CalibrationMetrics\n",
    "\n",
    "# Evaluate calibration\n",
    "calibration_evaluator = CalibrationMetrics(n_bins=10)\n",
    "cal_metrics = calibration_evaluator.evaluate_calibration(test_sample['isFraud'], probs)\n",
    "\n",
    "print(\"Calibration metrics:\")\n",
    "for metric, value in cal_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Plot calibration curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    test_sample['isFraud'], probs, n_bins=10\n",
    ")\n",
    "\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", linewidth=2, label=\"Model\")\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "plt.xlabel(\"Mean Predicted Probability\")\n",
    "plt.ylabel(\"Fraction of Positives\")\n",
    "plt.title(\"Calibration Plot\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(probs, bins=20, alpha=0.7, density=True)\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Prediction Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the key capabilities of the temporal drift-aware fraud detection system:\n",
    "\n",
    "1. **Temporal Pattern Analysis**: Understanding how fraud patterns evolve over time\n",
    "2. **Advanced Feature Engineering**: Creating time-aware and interaction features\n",
    "3. **Adversarial Validation**: Detecting distribution drift between time periods\n",
    "4. **Ensemble Learning**: Combining multiple models with dynamic weighting\n",
    "5. **Drift-Aware Predictions**: Making predictions while monitoring reliability\n",
    "6. **Model Interpretability**: Understanding individual model contributions\n",
    "7. **Calibration Assessment**: Ensuring probabilistic outputs are well-calibrated\n",
    "\n",
    "The system provides a production-ready framework for fraud detection that explicitly handles the challenge of temporal drift, ensuring robust performance as data distributions evolve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}